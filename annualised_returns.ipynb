{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Annualised Returns for all Zipcodes in the Train Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the data_retrieval_and_eda notebook in order to generate the train dataset.\n",
    "%run ./data_retrieval_and_eda.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset from the train.pickle file.\n",
    "with open('train.pickle', 'rb') as f:\n",
    "    train_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_zips = len(train_df['RegionName'].unique())\n",
    "\n",
    "print(f'There are {unique_zips} unique zipcodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the columns that are unnecesary to calculate annualised returns.\n",
    "\n",
    "train_df.drop(['RegionID', 'City', 'State', 'Metro', 'CountyName', 'SizeRank'], \n",
    "             axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate annualised returns, we will be subseting the dataframe to only include values for the first month of the year from 2012 until 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returning the range for the years under analysis\n",
    "years = range(2012, 2019)\n",
    "#creating a list which will contain each year's first date. \n",
    "year_month_list = [datetime.strptime(f'{year}-01-01', '%Y-%m-%d').date() for year in years]\n",
    "#subseting the train dataframe to only include the specified dates in year_month_list\n",
    "train_foy = train_df.loc[train_df['time'].isin(year_month_list)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate annualised returns we have to perform the following calculations: \n",
    "\n",
    "    1. Calculate YoY return: y1 = (x2-x1)/x1 or y1 = (x2/x1)-1 \n",
    "        1.1 x1 will represent each beginning year value 2012-01-01, 2013-01-01, ..., 2017-01-01\n",
    "        1.2 x2 will represent each ending year value 2013-01-01, 2014-01-01, ..., 2018-01-01\n",
    "    \n",
    "    2. Calculate the compound return: (1+y1)(1+y2)...(1+yN)^1/number of periods (years)\n",
    "        2.2 (1+y1) can be represented the following ways: (1+((x2-x1)/x1)) = ((1+(x2/x1)-1) = (x2/x1)\n",
    "        2.3 Therefore, the compound becomes: (x2/x1)(x3/x2)...(xN/x(N-1))^1/number of periods (years)\n",
    "    \n",
    "    3. Calculating the annualised return: compound return-1\n",
    "        3.1 ((1+y1)(1+y2)...(1+yN)^1/number of periods)-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating (x2/x1) for each year and for all the different zipcodes.\n",
    "\n",
    "train_foy['returns'] = train_foy['value'].div(train_foy.groupby('RegionName')['value'].shift(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the NaNs that have appeared in the year 2012, since that is the first year of data and we can't \n",
    "calculate the return from 2011 to 2012 (not in the dataset)\n",
    "\n",
    "NOTE: Some of the zipcodes don't have data dating back to 2012, therefore these NaN values are also dropped during the step above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the NaNs.\n",
    "\n",
    "train_foy = train_foy.dropna(subset=['returns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observing the YoY returns for the smallest zipcode in the dataset.\n",
    "\n",
    "train_foy.loc[(train_foy['RegionName'] == 1001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode_ann_returns = fn.annualised_returns(train_foy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising the distribution of annualised returns through a histogram\n",
    "\n",
    "plt.figure(figsize=(11, 7))\n",
    "plt.hist(zipcode_ann_returns['Ann_returns']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over15pct = zipcode_ann_returns[zipcode_ann_returns['Ann_returns'] > 0.15]\n",
    "print(f'The number of zipcodes that have yielded an annualised return of over 15% is {len(over15pct)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the sorted list of annualised returns into a pickle.\n",
    "\n",
    "with open('annualised_returns.pickle', 'wb') as f:\n",
    "    pickle.dump(zipcode_ann_returns, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
